{
  "name": "Nodestream.GitHub.io",
  "tagline": "Nodestream",
  "body": "[npm-badge]: https://badge.fury.io/js/nodestream.svg\r\n[npm-url]: https://npmjs.org/package/nodestream\r\n[travis-badge]: https://travis-ci.org/nodestream/nodestream.svg\r\n[travis-url]: https://travis-ci.org/nodestream/nodestream\r\n[coveralls-badge]: https://img.shields.io/coveralls/nodestream/nodestream.svg\r\n[coveralls-url]: https://coveralls.io/r/nodestream/nodestream\r\n[inch-badge]: http://inch-ci.org/github/nodestream/nodestream.svg\r\n[inch-url]: http://inch-ci.org/github/nodestream/nodestream\r\n[make-badge]: https://img.shields.io/badge/built%20with-GNU%20Make-brightgreen.svg\r\n[ns-fs]: https://github.com/nodestream/nodestream-filesystem\r\n[fs-icon]: https://cloud.githubusercontent.com/assets/3058150/13901081/d81b824c-ee17-11e5-8fbe-40eff40646f7.png\r\n[ns-s3]: https://github.com/nodestream/nodestream-s3\r\n[s3-icon]: https://cloud.githubusercontent.com/assets/3058150/13901098/80692616-ee18-11e5-98c1-91c35b936c51.png\r\n[ns-gridfs]: https://github.com/nodestream/nodestream-gridfs\r\n[gridfs-icon]: https://cloud.githubusercontent.com/assets/3058150/13901696/59652146-ee2c-11e5-8c7e-3cba5ba9854c.png\r\n[ns-gcs]: https://github.com/nodestream/nodestream-gcs\r\n[gcs-icon]: https://cloud.githubusercontent.com/assets/3058150/13907413/bfb554e0-eeed-11e5-9e51-ce490fad8abd.png\r\n\r\n# Nodestream\r\n\r\n[![NPM Version][npm-badge]][npm-url]\r\n[![Build Status][travis-badge]][travis-url]\r\n[![Coverage Status][coveralls-badge]][coveralls-url]\r\n[![Documentation Status][inch-badge]][inch-url]\r\n![Built with GNU Make][make-badge]\r\n\r\n> Streaming library for binary data transfers\r\n\r\n## Description\r\n\r\nThis library aims to provide an abstraction layer between your application/library and all the various remote storage services which exist on the market, either as hosted by 3rd parties or self-hosted (S3, GridFS etc.). Your code should not depend on these services directly - the code responsible for uploading a file should remain the same no matter which storage service you decide to use. The only thing that can change is the configuration.\r\n\r\n## Adapters\r\n\r\n| [![S3][s3-icon]][ns-s3] | [![GridFS][gridfs-icon]][ns-gridfs] | [![GCS][gcs-icon]][ns-gcs] | [![Filesystem][fs-icon]][ns-fs] |\r\n|:-----------------------:|:-----------------------------------:|:--------------------------:|:-------------------------------:|\r\n| Amazon S3               | GridFS (WIP)                        | Google Cloud Storage       | Local Filesystem                |\r\n\r\n## Usage\r\n\r\n### Installation\r\n\r\nThe first step is to install nodestream into your project:\r\n\r\n`npm install --save nodestream`\r\n\r\nThe next thing is to decide which *adapter* you want to use. An adapter is an interface for nodestream to be able to interact with a particular storage system. Let's use local filesystem for a start:\r\n\r\n`npm install --save nodestream-filesystem`\r\n\r\n### Configuration\r\n\r\nLet's create and configure a nodestream instance with which your application can then interact:\r\n\r\n```js\r\n// Require the main Nodestream class\r\nconst Nodestream = require('nodestream')\r\nconst nodestream = new Nodestream({\r\n  // This tells nodestream which storage system it should interact with\r\n  // Under the hood, it will try to require `nodestream-filesystem` module\r\n  adapter: 'filesystem',\r\n  // This object is always specific to your adapter of choice - always check\r\n  // the documentation for that adapter for available options\r\n  config: {\r\n    // You MUST provide either an absolute path or nothing at all\r\n    // You can use array notation, the parts will be joined for you\r\n    root: [__dirname, '.storage']\r\n  }\r\n})\r\n```\r\n\r\nGreat! At this point, nodestream is ready to transfer some bytes!\r\n\r\n### Usage\r\n\r\n#### Uploading\r\n\r\nYou can upload any kind of readable stream. Nodestream does not care where that stream comes from, whether it's an http upload or a file from your filesystem or something totally different.\r\n\r\nFor this example, we will upload a file from our filesystem.\r\n\r\n> We will be uploading the file to our local filesystem as well as reading it from the same filesystem. Normally you would probably use a source different from the target storage, but Nodestream does not really care.\r\n\r\n```js\r\nconst fs = require('fs')\r\n// This is the file we will upload - create a readable stream of that file\r\nconst profilePic = fs.createReadStream('/users/me/pictures/awesome-pic.png')\r\n\r\nnodestream.upload(profilePic, {\r\n  // directory and name are supported by all storage adapters, but each\r\n  // adapter might have additional options you can use\r\n  directory: 'avatars',\r\n  name: 'user-123.png'\r\n})\r\n.then(results => {\r\n  // results can contain several properties, but the most interesting\r\n  // and always-present is `location` - you should definitely save this\r\n  // somewhere, you will need it to retrieve this file later!\r\n  console.log(results.location)\r\n})\r\n.catch(err => {\r\n  // U-oh, something blew up ðŸ˜±\r\n})\r\n```\r\n\r\nCongratulations, you just uploaded your first file!\r\n\r\n#### Downloading\r\n\r\nDownloading a file is quite straight-forward - all you need is the file's location as returned by the `upload()` method and a destination stream to which you want to send the data. This can be any valid writable stream. Again, Nodestream does not care where you are sending the bytes, be it local filesystem, an http response or even a different Nodestream instance (ie. S3 to GridFS transfer).\r\n\r\n```js\r\n// Let's create a destination for the download\r\nconst fs = require('fs')\r\nconst destination = fs.createWriteStream('/users/me/downloads/picture.png')\r\n\r\n// We are hardcoding the location here, but you will probably want to\r\n// retrieve the file's location from a database\r\nnodestream.download('avatars/user-123.png', destination)\r\n.then(() => {\r\n  // All good, destination received all the data!\r\n})\r\n.catch(err => {\r\n  // Oh well...\r\n})\r\n```\r\n\r\n#### Removing\r\n\r\nJust pass the file's location to the `.remove()` method.\r\n\r\n```js\r\nnodestream.remove('avatars/user-123.png')\r\n.then(location => {\r\n  // The file at this location has just been removed!\r\n})\r\n.catch(err => {\r\n  // Oh no!\r\n})\r\n```\r\n\r\n### Transforms\r\n\r\nNodestream supports a feature called transforms. In principle, a transform is just a function that modifies the incoming or outgoing bytes in some way, transparently for each stream passing through Nodestream. Some use cases:\r\n\r\n- Calculating checksums\r\n- Compressing/decompressing data\r\n- Modifying the data completely, ie. appending headers/footers and whatnot\r\n\r\n#### Registering a transform\r\n\r\nWhen you configure your Nodestream instance, you should register transforms using the `.addTransform()` function.\r\n\r\n```js\r\n// The first argument defines when the transform should be applied ('upload', 'download')\r\n// The second argument is the transform's name - Nodestream will attempt to require\r\n// `nodestream-transform-compress` under the hood, so make sure you have it installed!\r\n// The third argument is an option configuration object which will be passed as-is to\r\n// the transform stream when the time comes to use the transform.\r\nnodestream.addTransform('upload', 'compress', { mode: 'compress' })\r\nnodestream.addTransform('download', 'compress', { mode: 'decompress' })\r\n```\r\n\r\nNow, every time you call `.upload()` or `.download()`, the respective transform will be applied on the stream.\r\n\r\nFor uploads, a transform can optionally publish some data about the applied transformations onto the `results` object.\r\n\r\nThere is no limit to the amount of transforms which can be registered per Nodestream instance.\r\n\r\n## License\r\n\r\nThis software is licensed under the **BSD-3-Clause License**.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}